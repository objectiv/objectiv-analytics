{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8229aa62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import datetime\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "import sqlalchemy\n",
    "\n",
    "# import Objectiv buh_tuh\n",
    "from buhtuh import BuhTuhDataFrame\n",
    "sys.path.extend([\n",
    "    '../../buhtuh',\n",
    "    '../'\n",
    "])\n",
    "\n",
    "from objectiv_buhtuh.util import duplo_basic_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8b47e4-e1c6-443f-a164-31078ed3ae8b",
   "metadata": {},
   "source": [
    "## Get website production data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e2a831",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get some data, add database and credentials here\n",
    "engine = sqlalchemy.create_engine('postgresql://objectiv:@localhost:5432/objectiv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8310a973",
   "metadata": {},
   "outputs": [],
   "source": [
    "## production website data (from sessionized_data + features)\n",
    "basic_features = duplo_basic_features()\n",
    "full_df = BuhTuhDataFrame.from_model(engine=engine, model=basic_features, index=['event_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237a13bf-52e0-4082-a4a2-c382871b1713",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Set the timeframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3177f1fb-c741-4269-8086-dbab942afbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the timeframe for analysis\n",
    "selector = (full_df['moment'] >= datetime.date(2021,6,1)) & (full_df['moment'] < datetime.date(2021,10,11))\n",
    "\n",
    "# create one sampled df with timeframe applied \n",
    "timeframe_df = full_df[selector]\n",
    "\n",
    "timeframe_df.sort_values(by='moment', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1d4954-cabc-44e7-81b8-d18f9d303ed9",
   "metadata": {},
   "source": [
    "## Set the time aggregation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a697920-a443-4593-8acd-71c514aa7406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose for which level of time aggregation the rest of the analysis will run\n",
    "# supports all Postgres datetime template patterns:\n",
    "# https://www.postgresql.org/docs/9.1/functions-formatting.html#FUNCTIONS-FORMATTING-DATETIME-TABLE\n",
    "\n",
    "agg_level = 'YYYYIW'\n",
    "\n",
    "# add the time aggregation as new column to the dataframes, so we can group on this later\n",
    "timeframe_df['time_aggregation'] = timeframe_df['moment'].format(agg_level)\n",
    "full_df['time_aggregation'] = full_df['moment'].format(agg_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0697e0d3-8443-427b-a3a9-09342adf624e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e00ffd-9940-4ff3-b5db-2734730f240e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate unique users \n",
    "users = timeframe_df.groupby('time_aggregation').aggregate({'user_id':'nunique'})\n",
    "\n",
    "users.sort_values(by='time_aggregation', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951d9b1e-5159-416d-a904-75b63b795e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize users\n",
    "users.sort_values(by='time_aggregation', ascending=True).head(60).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378f5454-f7c7-409b-a6d0-996e078c851a",
   "metadata": {},
   "source": [
    "## Sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c3c2a3-9616-43d6-b529-acf5f6d210d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate unique sessions\n",
    "sessions = timeframe_df.groupby('time_aggregation').aggregate({'session_id':'nunique'})\n",
    "\n",
    "sessions.sort_values(by='time_aggregation', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560fc334-17c9-4604-85dd-24fa43abaf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize sessions\n",
    "sessions.sort_values('time_aggregation', ascending=True).head(60).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6888435d-4287-4cdc-8767-985fe2b9c216",
   "metadata": {},
   "source": [
    "## Sessions per user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77706040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge users and sessions\n",
    "users_sessions = sessions.merge(users, how='inner', on='time_aggregation')\n",
    "\n",
    "# calculate average sessions per user\n",
    "users_sessions['sessions_per_user_avg'] = users_sessions['session_id_nunique'] / users_sessions['user_id_nunique']\n",
    "\n",
    "# clean-up columns\n",
    "del(users_sessions['session_id_nunique'])\n",
    "del(users_sessions['user_id_nunique'])\n",
    "\n",
    "users_sessions.sort_values('time_aggregation', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7d52d8-08df-4133-a2da-6cedd81f22fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize average sessions per user\n",
    "users_sessions.sort_values(by='time_aggregation', ascending=True).head(60).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbaaf82-ee41-4602-a2cd-f622fa84b0b2",
   "metadata": {},
   "source": [
    "## New users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d917e1a3-5b16-4365-98e0-ea0040babebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define first seen per user, based on full dataset\n",
    "user_first_seen = full_df.groupby('user_id').aggregate({'time_aggregation':'min'})\n",
    "\n",
    "# calculate new users for each timeframe\n",
    "new_users = user_first_seen.groupby('time_aggregation_min').aggregate({'user_id':'nunique'})\n",
    "\n",
    "# merge with total users, to calculate ratio and limit to timerange\n",
    "new_total_users = users.merge(new_users, how='inner', left_on='time_aggregation', right_on='time_aggregation_min', suffixes=('_total', '_new'))\n",
    "\n",
    "# NOTE: also would be good to delete the index column time_aggregation_min, but we have no function for this yet\n",
    "\n",
    "# calculate new & returning user share\n",
    "new_total_users['new_user_share'] = new_total_users['user_id_nunique_new'] / new_total_users['user_id_nunique_total']\n",
    "new_total_users['returning_user_share'] = (new_total_users['user_id_nunique_total'] - new_total_users['user_id_nunique_new']) / new_total_users['user_id_nunique_total']\n",
    "\n",
    "new_total_users.sort_values(by='time_aggregation', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca9d062-dd61-49c2-b669-bf0f45c68451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize new users\n",
    "new_total_users[['user_id_nunique_new', 'user_id_nunique_total']].sort_values(by='time_aggregation', ascending=True).head(60).plot()\n",
    "\n",
    "# NOTE: also would be good to delete the index column time_aggregation_min, but we have no function for this yet, not the x-axis is showing twice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be740b11-d552-4501-b8b3-48cb077f8470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize returning users\n",
    "new_total_users[['returning_user_share']].sort_values(by='time_aggregation', ascending=True).head(60).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b2a479-bd03-4cba-be97-83ccfbf38337",
   "metadata": {},
   "source": [
    "## Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8fc165-5b6a-4df4-839e-53b6df4084f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate total users\n",
    "# NOTE; this is not possible in pandas, and therefore not super intuitive. timeframe_df['user_id'].nunique() should be working, on the list\n",
    "total_users = timeframe_df['user_id'].nunique()\n",
    "\n",
    "# number of total sessions per user\n",
    "total_sessions_user = timeframe_df.groupby(['user_id']).aggregate({'session_id':'nunique'})\n",
    "\n",
    "# calculate frequency\n",
    "frequency = total_sessions_user.groupby(['session_id_nunique']).aggregate({'user_id':'nunique'})\n",
    "\n",
    "# add total users and calculate share per number of sessions\n",
    "frequency['share_of_users'] = frequency['user_id_nunique'] / total_users[1]\n",
    "\n",
    "frequency.sort_values(by='session_id_nunique', ascending=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771461f0-9cc6-482e-ada3-76a4da4152de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize frequency\n",
    "frequency[['share_of_users']].sort_values(by='session_id_nunique', ascending=True).head(60).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046eb7e6-fba5-4048-ba17-8cff59d92b38",
   "metadata": {},
   "source": [
    "## Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c743b4-dae4-41b9-a4d5-15a87c3b295c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of total user and hits per feature\n",
    "users_per_event = timeframe_df.groupby(['time_aggregation', 'feature']).aggregate({'user_id':'nunique','session_hit_number':'count'})\n",
    "\n",
    "users_per_event.sort_values(by=['time_aggregation', 'user_id_nunique'], ascending=False).head()\n",
    "\n",
    "# TODO: \n",
    "# 1) add feature aggregation magic here, so we make the features show-off what we can do much more \n",
    "# 2) add location stack, showing the power of this very soon in the demo's"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acf9cf5-c4e6-4d71-a15d-64bea1bf4d55",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e09155-217c-4631-b528-ccb7be25ac43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: \n",
    "# We can do much better here once we integrate feature selection & aggregation\n",
    "\n",
    "# NOTE: WE NEED TO UPDATE THIS ONCE THE FIRST NEW EVENT FORMAT DATA COMES IN FOR A CONVERSION\n",
    "# set the goal event that you define as conversion, using our subcribe-to-mailing\n",
    "conv_selector = (timeframe_df['feature'] == '(WebDocumentContext,#document),(InputContext,keep-me-posted-input),(ButtonContext,subscribe)')\n",
    "\n",
    "# create df with only conversion events\n",
    "conversions_df = timeframe_df[conv_selector]\n",
    "\n",
    "# calculate conversions, now per user, but can easily be aggregated to session_id instead\n",
    "conversions = conversions_df.groupby('time_aggregation').aggregate({'user_id':'nunique'})\n",
    "\n",
    "# merge with users, but can easily be done with sessions instead\n",
    "conversion_rate = conversions.merge(users, how='inner', on='time_aggregation', suffixes=('_converting', '_total'))\n",
    "\n",
    "# calculate conversion rate\n",
    "conversion_rate['conversion_rate'] = conversion_rate['user_id_nunique_converting'] / conversion_rate['user_id_nunique_total']\n",
    "\n",
    "conversion_rate.sort_values(by='time_aggregation', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91715bec-e0c2-4abc-b049-0b7b590348ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize conversion rate\n",
    "conversion_rate[['conversion_rate']].sort_values(by='time_aggregation', ascending=True).head(60).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cdb781-d188-4f7c-b85d-d96262ff7e69",
   "metadata": {},
   "source": [
    "## Bounce rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f81a91-e85c-4f96-b534-dd39fdacf55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: we need to limit this to page or screen views, instead of all events. Do this once we have integration feature selection.\n",
    "\n",
    "# gather sessions, hits per timeframe\n",
    "hits_sessions = timeframe_df[['time_aggregation', 'session_id', 'session_hit_number']]\n",
    "\n",
    "# calculate hits per session\n",
    "hits_per_session = hits_sessions.groupby(['time_aggregation', 'session_id']).aggregate({'session_hit_number':'nunique'})\n",
    "\n",
    "# select sessions with only one hit\n",
    "hit_selector = (hits_per_session['session_hit_number_nunique'] == 1)\n",
    "single_hit_sessions = hits_per_session[hit_selector].to_frame()\n",
    "\n",
    "# count these single hit sessions per timeframe\n",
    "bounced_sessions = single_hit_sessions.groupby('time_aggregation').aggregate({'session_id':'nunique'})\n",
    "\n",
    "# merge with total sessions\n",
    "bounce_rate = bounced_sessions.merge(sessions, how='inner', on='time_aggregation', suffixes=('_bounce', '_total'))\n",
    "\n",
    "# calculate bounce rate\n",
    "bounce_rate['bounce_rate'] = bounce_rate['session_id_nunique_bounce'] / bounce_rate['session_id_nunique_total']\n",
    "\n",
    "bounce_rate.sort_values(by='time_aggregation', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d126de4-cb9d-4f94-8d54-4074721385db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize bounce rate\n",
    "bounce_rate[['bounce_rate']].sort_values(by='time_aggregation', ascending=True).head(60).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c06f91-3fe1-4e25-8706-601e1b223393",
   "metadata": {},
   "source": [
    "## Session duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2279e793-e5a4-4a4b-968a-db8c5949f0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate duration of each session\n",
    "# NOTE: we want this to work, but that is a bug, on the list:\n",
    "session_duration = timeframe_df.groupby(['session_id']).aggregate({'moment':['min','max'], 'time_aggregation':'min'})\n",
    "\n",
    "session_duration['session_duration'] = session_duration['moment_max'] - session_duration['moment_min']\n",
    "\n",
    "# check which sessions have duration of zero\n",
    "# NOTE: not very intuitive. on the list to improve\n",
    "session_duration['session_duration_zero'] = session_duration['session_duration'] == '0'\n",
    "\n",
    "# calculate average session duration\n",
    "avg_session_duration = session_duration.groupby(['time_aggregation_min', 'session_duration_zero'])\\\n",
    "        .aggregate({'session_duration': 'mean', 'session_id': 'count'})\n",
    "\n",
    "# merge with total sessions and calculate share\n",
    "duration_breakdown = avg_session_duration.merge(sessions, how='inner', left_on='time_aggregation_min', right_on='time_aggregation')\n",
    "\n",
    "# clean-up and rename columns\n",
    "duration_breakdown['share_of_sessions'] = duration_breakdown['session_id_count'] / duration_breakdown['session_id_nunique']\n",
    "del(duration_breakdown['session_id_nunique'])\n",
    "\n",
    "duration_breakdown.sort_values(by='time_aggregation_min', ascending=False).head(6)\n",
    "\n",
    "# NOTE: also would be good to delete the index column time_aggregation, but we have no function for this yet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f0f2c5-8e20-4b54-bdfa-dcb920794e5d",
   "metadata": {},
   "source": [
    "## Session duration between events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bb0024-91db-4a8b-a045-21934c117020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the start and stop events to measure the duration in between\n",
    "start_event = '(WebDocumentContext,#document)'\n",
    "stop_event = '(WebDocumentContext,#document),(SectionContext,footer)'\n",
    "\n",
    "# filter on only these events\n",
    "start_stop = timeframe_df[(timeframe_df.feature == start_event) | (timeframe_df.feature == stop_event)]\n",
    "\n",
    "# get previous (because of the sorting) event for stop event _in the same session, window_lag(n) returns the nth previous value in the partition\n",
    "window = start_stop.sort_values('moment').window('session_id')\n",
    "start_stop['prev_event'] = start_stop.feature.window_lag(window)\n",
    "start_stop['prev_moment'] = start_stop.moment.window_lag(window)\n",
    "\n",
    "# create a copy of this df with as base_node the current df's state\n",
    "# note: this is a temp fix until we automatically create a new node\n",
    "start_stop = start_stop.get_df_materialized_model()\n",
    "\n",
    "# filter: for each stop event, select the closest preceeding start event\n",
    "complete = start_stop[(start_stop.feature == stop_event) & (start_stop.prev_event == start_event)]\n",
    "\n",
    "# calculate duration\n",
    "complete['duration'] = complete.moment - complete.prev_moment\n",
    "\n",
    "# calculate average duration per timeframe\n",
    "duration_between_events = complete.groupby('time_aggregation').aggregate({'duration':'mean'})\n",
    "\n",
    "duration_between_events.sort_values(by='time_aggregation', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e283e6-cc77-412d-91ec-9915fcbc7764",
   "metadata": {},
   "source": [
    "## Retention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9274e78b-c981-49f4-b30d-1a5729dc6268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select all active moments for each user\n",
    "user_moments = timeframe_df.groupby(['user_id', 'time_aggregation']).aggregate({'moment':'count'})\n",
    "\n",
    "# merge with first seen df\n",
    "user_activity = user_moments.merge(user_first_seen, how='inner', on='user_id')\n",
    "\n",
    "# clean-up and rename columns\n",
    "user_activity['new_user_cohort'] = user_activity['time_aggregation_min']\n",
    "del(user_activity['time_aggregation_min'])\n",
    "del(user_activity['moment_count'])  \n",
    "\n",
    "# for each new_user_cohort count how many users get back per timeframe\n",
    "retention_input = user_activity.groupby(['new_user_cohort', 'time_aggregation']).aggregate({'user_id':'nunique'})\n",
    "\n",
    "# add the size of each new user cohort\n",
    "cohorts = retention_input.merge(new_users, how='inner', left_on='new_user_cohort', right_on='time_aggregation_min', suffixes=('_active', '_cohort'))\n",
    "\n",
    "# NOTE: after we can rename/delete an index, remove the time_aggregation_min column here, it's duplicate\n",
    "\n",
    "# calculate classic retention (so not rolling retention, where users are required to be active each timeframe)\n",
    "cohorts['retention'] = cohorts['user_id_nunique_active'] / cohorts['user_id_nunique_cohort']\n",
    "\n",
    "# now switch to Pandas, as the dataset is small enough\n",
    "cohorts_df = cohorts.to_df().reset_index()\n",
    "\n",
    "# create typical retention matrix\n",
    "cohorts_df = cohorts_df.astype({'new_user_cohort': 'int', 'time_aggregation': 'int'})\n",
    "cohorts_df['active_in_timeframe'] = cohorts_df.time_aggregation - cohorts_df.new_user_cohort\n",
    "cohorts_df.pivot('new_user_cohort', 'active_in_timeframe', 'retention')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2c66a2-97ee-4888-83d2-122547bf53c6",
   "metadata": {},
   "source": [
    "## User timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c13effa-fbc1-42fb-8faf-85c40948602b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the timeline of an indivual user's events\n",
    "# NOTE: we can make this better with feature selection & aggregation\n",
    "\n",
    "# select the spefic user we want to replay\n",
    "# NOTE: .astype('string') is more something buhtuh should handle, on list\n",
    "user_selector = (timeframe_df['user_id'].astype('string') == '320db8ee-847c-424b-8291-c65d021575aa')\n",
    "\n",
    "# create df with only this user's events\n",
    "selected_user_df = timeframe_df[user_selector]\n",
    "\n",
    "# NOTE: we can apply feature selection and maybe sankey visual here\n",
    "# timeline of this user's events\n",
    "user_timeline = selected_user_df[['moment','feature']]\n",
    "\n",
    "user_timeline.sort_values(by='moment', ascending=True).head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f25752-6cbe-4119-ac7e-79d4c095e793",
   "metadata": {},
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95769feb-fc26-4aa1-9e12-205aa3ed7fc8",
   "metadata": {},
   "source": [
    "## WIP Recency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d3fef3-e4d7-4adf-a8c3-ca4c4d789606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select all active days for each user\n",
    "user_days = timeframe_df.groupby(['user_id', 'day'])['session_id'].nunique()\n",
    "\n",
    "user_days['day_copy'] = user_days.index['day']\n",
    "\n",
    "# get previous (because of the sorting) day for each user\n",
    "# window = user_days.sort_values('day').window('user_id')\n",
    "# user_days['prev_day'] = user_days.day.window_lag(window)\n",
    "\n",
    "#user_days.head()\n",
    "# create a copy of this df with as base_node the current df's state\n",
    "# note: this is a temp fix until we automatically create a new node\n",
    "#start_stop = start_stop.get_df_materialized_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a504f06-ce9b-44d0-b1e1-bc4047a51843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# below parts first require some next steps in dub_buh_tuh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf27126-3491-4468-ac8f-5b2df69d28c7",
   "metadata": {},
   "source": [
    "## WIP Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6389f4b-0bb6-4692-b865-3f64aa0ef26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# timeframe_df.global_contexts.json.get_value('ApplicationContext').head()\n",
    "\n",
    "timeframe_df.global_contexts.json[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84339df-e25a-43ff-a527-8ff7aa674128",
   "metadata": {},
   "source": [
    "## Conversion funnel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2ea3f2-a2b0-4701-80fe-3cce1e54b69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Self-merge is giving not the ouput we expect. \n",
    "# Without that, we can not create a sankey that looks like a familiar funnel. \n",
    "# See example here https://gitlab.com/newrelity/objectiv-taxonomy-prototypes/-/blob/web-analytics/data-science/issue_example_self_merge.ipynb\n",
    "\n",
    "# showing the sequence of events for converting users\n",
    "\n",
    "# resuse the df with only conversion events, select the users and their conversion moment\n",
    "converting_users = conversions_df['user_id', 'moment']\n",
    "\n",
    "# for now, we focus on the first conversion event. Later it is nice to also make it possible to see events between first and 2nd conversion, and so on.\n",
    "converting_users = converting_users.groupby(['user_id'])['moment'].min()\n",
    "converting_users['first_conversion_moment'] = converting_users['moment_min']\n",
    "del(converting_users['moment_min'])\n",
    "\n",
    "# merge with the df that has all user events in the timeframe\n",
    "converting_users_events = timeframe_df.merge(converting_users, [('user_id', 'user_id')])\n",
    "\n",
    "# select all events that converting users had up to their first conversion moment\n",
    "event_selector = (converting_users_events['moment'] <= converting_users_events['first_conversion_moment'])\n",
    "pre_conversion_events = converting_users_events[event_selector]\n",
    "\n",
    "# create pairs of from-to events based on session hit number\n",
    "event_sequence = pre_conversion_events['session_id', 'session_hit_number', 'feature']\n",
    "\n",
    "event_pairs = event_sequence.merge(event_sequence, [('session_id')])\n",
    "\n",
    "event_pairs.head(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8ae37e-d3a9-4ff4-a812-58344f07c7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sank = pd.read_csv('buh.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7547db-3fad-412c-b566-01f5582dccdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = set(df_sank['source']).union(set(df_sank['target']))\n",
    "df_sank['source'] = pd.Categorical(df_sank['source'], categories=categories)\n",
    "df_sank['target'] = pd.Categorical(df_sank['target'], categories=categories)\n",
    "\n",
    "text_in_title = str('title')\n",
    "node = dict(\n",
    "      pad=15,\n",
    "      thickness=20,\n",
    "      line=dict(color=\"black\", width=0.5),\n",
    "      label=df_sank.source.cat.categories,\n",
    "      color='blue'\n",
    "    )\n",
    "link = pd.concat([df_sank[['source', 'target']].apply(lambda x: x.cat.codes), df_sank['value']], axis=1).to_dict('list')\n",
    "fig = go.Figure(go.Sankey(arrangement=\"fixed\", link=link, node=node), {'clickmode': 'event+select'})\n",
    "fig.update_layout(title_text=text_in_title, font_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ec41a8-09bc-4922-b12f-83dd1725bf67",
   "metadata": {},
   "source": [
    "## Events flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106f06c4-ac0f-4c6b-889b-918cba8be266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# events per session hit number\n",
    "events_per_hit_number = timeframe_df[selector].groupby(['session_hit_number', 'feature'])['session_id'].nunique()\n",
    "\n",
    "events_per_hit_number.sort_values({'session_hit_number':True}).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6589de70-d5d2-4b1b-8529-ed12c0d3e898",
   "metadata": {},
   "source": [
    "## Traffic source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d42d550-625b-451f-8cb4-fed192483469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# For Traffic Source, Geo and Device metrics, we would need to get source/geo/device data from GlobalContext in a easy way.\n",
    "# We can then also blend it in all metrics above as slicing option."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56cb88f-b2df-44e2-80ba-c1c384978689",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Geo "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a12b72-3872-488c-934d-eed3f262560e",
   "metadata": {},
   "source": [
    "## Devices"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
